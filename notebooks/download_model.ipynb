{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3050 Laptop GPU, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from ../models/7B/llama-7b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_head_kv  = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 5.0e-06\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: using CUDA for GPU acceleration\n",
      "llama_model_load_internal: mem required  = 2180.23 MB (+  256.00 MB per state)\n",
      "llama_model_load_internal: allocating batch_size x (512 kB + n_ctx x 128 B) = 288 MB VRAM for the scratch buffer\n",
      "llama_model_load_internal: offloading 16 repeating layers to GPU\n",
      "llama_model_load_internal: offloaded 16/35 layers to GPU\n",
      "llama_model_load_internal: total VRAM used: 2026 MB\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/7B/llama-7b.ggmlv3.q4_0.bin\"\n",
    "llm = Llama(\n",
    "    model_path=model_path, \n",
    "    n_gpu_layers=16,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"cmpl-ebf11e25-103d-4afe-ae73-7d2fa10f7ba2\",\n",
      "    \"object\": \"text_completion\",\n",
      "    \"created\": 1692867916,\n",
      "    \"model\": \"../models/7B/llama-7b.ggmlv3.q4_0.bin\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"text\": \" Hơn giờ học sinh đến, đâu có nguy hiểm.\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\"\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 18,\n",
      "        \"completion_tokens\": 27,\n",
      "        \"total_tokens\": 45\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   815.16 ms\n",
      "llama_print_timings:      sample time =    11.73 ms /    28 runs   (    0.42 ms per token,  2387.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2378.11 ms /    28 runs   (   84.93 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =  2429.17 ms\n"
     ]
    }
   ],
   "source": [
    "output = llm(\n",
    "    \"Translate the following sentence to Vietnamese: I go to school. Vietnamese:\", \n",
    "    max_tokens=1024,\n",
    "    stop=[\"Q:\", \"\\n\"],\n",
    "    echo=False,\n",
    ")\n",
    "print(json.dumps(output, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   815.16 ms\n",
      "llama_print_timings:      sample time =    57.08 ms /   128 runs   (    0.45 ms per token,  2242.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   819.42 ms /    15 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time = 10575.96 ms /   127 runs   (   83.28 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time = 11641.73 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-8a9bfa55-3495-4f3f-8ce9-ffdfe7ae76cb',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1692867925,\n",
       " 'model': '../models/7B/llama-7b.ggmlv3.q4_0.bin',\n",
       " 'choices': [{'text': '\\nIs there any recordings of Stephen Colbert and John Oliver going at it in a rap battle?\\n\\nAnswer: Colbert and Oliver have had several \"rap battles\". See [here](http://www.colbertnation.com/the-colbert-report-videos/432698/april-10-2015/) for one example.\\n\\nComment: This does not provide an answer to the question. To critique or request clarification from an author, leave a comment below their post - you can always comment on your own posts, and once you have',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'length'}],\n",
       " 'usage': {'prompt_tokens': 16, 'completion_tokens': 128, 'total_tokens': 144}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Question: A rap battle between Stephen Colbert and John Oliver\n",
    "\"\"\"\n",
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
